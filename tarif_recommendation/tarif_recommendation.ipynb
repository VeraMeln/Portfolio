{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендация тарифов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оператор мобильной связи «Мегалайн» выяснил: многие клиенты пользуются архивными тарифами. Они хотят построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В вашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы (из проекта курса «Статистический анализ данных»). Нужно построить модель для задачи классификации, которая выберет подходящий тариф. Предобработка данных не понадобится — вы её уже сделали."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте модель с максимально большим значением *accuracy*. Чтобы сдать проект успешно, нужно довести долю правильных ответов по крайней мере до 0.75. Проверьте *accuracy* на тестовой выборке самостоятельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим на имеющихся данных несколько моделей с разными гиперпараметрами. Проверим их качество на валидационной выборке и выберем лучшую из тех, чья доля правильных ответов превысит 0,75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект в наборе данных — это информация о поведении одного пользователя за месяц. \n",
    "\n",
    "Известно:\n",
    "- сalls — количество звонков,\n",
    "- minutes — суммарная длительность звонков в минутах,\n",
    "- messages — количество sms-сообщений,\n",
    "- mb_used — израсходованный интернет-трафик в Мб,\n",
    "- is_ultra — каким тарифом пользовался в течение месяца («Ультра» — 1, «Смарт» — 0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем необходимые библиотеки и методы\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Откройте и изучите файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# откроем файл и посмотрим первые 5 строк\n",
    "data = pd.read_csv('/datasets/users_behavior.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# посмотрим основную информацию об имеющемся наборе данных\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# посмотрим, что собой представляют числовые значения имеющихся характеристик данных\n",
    "data.hist(figsize=(9, 15));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836\n",
       "std      33.236368   234.569872    36.148326   7570.968246\n",
       "min       0.000000     0.000000     0.000000      0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500\n",
       "50%      62.000000   430.600000    30.000000  16943.235000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим, как распределились значения количественных признаков\n",
    "data.loc[:, 'calls':'mb_used'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете представлена информация о 3214 пользователях. Данные прошли предобработку, пропусков не содержат.\n",
    "\n",
    "Среднестатистический пользователь за месяц: совершает 62 звонка, тратит на разговоры 430 минут, отправляет 30 сообщений и тратит 16 Гб интернет-траффика.\n",
    "\n",
    "Пользователи выбирают тариф «Смарт» более чем в 2 раза чаще, чем тариф «Ультра»."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбейте данные на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделим исходные данные на обучающую, валидационную и тестовую выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобьем данные на три части – обучающую выборку, валидационную и тестовую в отношении 3:1:1. \n",
    "\n",
    "Сначала отделим 60% в качестве обучающего набора, затем оставшиеся данные разделим пополам.\n",
    "\n",
    "Так как в наших данных тариф «Смарт» встречается более чем в 2 раза чаще, чем тариф «Ультра», передадим функции train_test_split столбец «is_ultra» в качестве значения параметра stratify, чтобы это соотношение сохранилось после разделения данных на две выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_rest = train_test_split(\n",
    "    data,\n",
    "    test_size=0.4,\n",
    "    random_state=12345,\n",
    "    stratify=data['is_ultra']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 1928, 1286)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# убедимся в правильности разбиения\n",
    "data.shape[0], data_train.shape[0], data_rest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.693528\n",
       "1    0.306472\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим соотношения значений 0 и 1 в столбце 'is_ultra' в исходном и в двух получившихся наборах\n",
    "data['is_ultra'].value_counts()/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.693465\n",
       "1    0.306535\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['is_ultra'].value_counts()/data_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.693624\n",
       "1    0.306376\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rest['is_ultra'].value_counts()/data_rest.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Соотношение классов 0 (соответствует тарифу «Смарт») и 1 (соответствует тарифу «Ультра») во всех трех наборах сохранилось с точностью до трех знаков после запятой.\n",
    "\n",
    "Теперь разобьем data_rest на валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_valid, data_test = train_test_split(\n",
    "    data_rest,\n",
    "    test_size=0.5,\n",
    "    random_state=12345,\n",
    "    stratify=data_rest['is_ultra']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.693624\n",
       "1    0.306376\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим, соотношения значений 0 и 1 в столбце 'is_ultra' в валидационной и тестовой выборках\n",
    "# соответствуют превоначальным\n",
    "data_valid['is_ultra'].value_counts()/data_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.693624\n",
       "1    0.306376\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['is_ultra'].value_counts()/data_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полное соответствие пропорциям из data_rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделим обучающие признаки и целевой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим отдельные переменные для обучающих признаков и целевого признака для каждого из трех наборов данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = data_train.drop('is_ultra', axis=1)\n",
    "target_train = data_train['is_ultra']\n",
    "\n",
    "features_valid = data_valid.drop('is_ultra', axis=1)\n",
    "target_valid = data_valid['is_ultra']\n",
    "\n",
    "features_test = data_test.drop('is_ultra', axis=1)\n",
    "target_test = data_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. На данном шаге мы разделили исходные данные на три части – обучающую выборку, валидационную и тестовую в отношении 3:1:1. Соотношение данных по разным тарифам при этом сохранилось. \n",
    "1. Для каждого набора данных выделили обучающие признаки и целевой в различные переменные.\n",
    "\n",
    "Можно переходить к настройкам моделей и их обучению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исследуйте модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заведем массив, в который будем сохранять лучшие модели каждого вида, если доля их правильных ответов превысит 0,75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификации с использованием дерева решений попробуем различные настройки следующих параметров: глубина дерева и количество характеристик, которые учитываются при поиске лучшего разбиения. \n",
    "\n",
    "Посмотрим разные варианты сочетания этих параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth \t max_feat \t accuracy_score\n",
      "1 \t 1 \t 0.7527216174183515\n",
      "1 \t 2 \t 0.7527216174183515\n",
      "1 \t 3 \t 0.7402799377916018\n",
      "1 \t 4 \t 0.7402799377916018\n",
      "1 \t sqrt \t 0.7527216174183515\n",
      "1 \t log2 \t 0.7527216174183515\n",
      "\n",
      "2 \t 1 \t 0.7807153965785381\n",
      "2 \t 2 \t 0.7527216174183515\n",
      "2 \t 3 \t 0.7822706065318819\n",
      "2 \t 4 \t 0.7729393468118196\n",
      "2 \t sqrt \t 0.7527216174183515\n",
      "2 \t log2 \t 0.7527216174183515\n",
      "\n",
      "3 \t 1 \t 0.7807153965785381\n",
      "3 \t 2 \t 0.7744945567651633\n",
      "3 \t 3 \t 0.7869362363919129\n",
      "3 \t 4 \t 0.7776049766718507\n",
      "3 \t sqrt \t 0.7744945567651633\n",
      "3 \t log2 \t 0.7744945567651633\n",
      "\n",
      "4 \t 1 \t 0.7807153965785381\n",
      "4 \t 2 \t 0.776049766718507\n",
      "4 \t 3 \t 0.7667185069984448\n",
      "4 \t 4 \t 0.7542768273716952\n",
      "4 \t sqrt \t 0.776049766718507\n",
      "4 \t log2 \t 0.776049766718507\n",
      "\n",
      "5 \t 1 \t 0.7884914463452566\n",
      "5 \t 2 \t 0.7822706065318819\n",
      "5 \t 3 \t 0.7931570762052877\n",
      "5 \t 4 \t 0.7853810264385692\n",
      "5 \t sqrt \t 0.7822706065318819\n",
      "5 \t log2 \t 0.7822706065318819\n",
      "\n",
      "--------------------------------------------------\n",
      "best results:\n",
      "5 \t 3 \t 0.7931570762052877\n",
      "best model: DecisionTreeClassifier(max_depth=5, max_features=3, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "# создаем переменные для лучшей на текущий момент модели и ее точности\n",
    "desision_tree_best_model = None\n",
    "best_result = 0\n",
    "\n",
    "print('depth','\\t', 'max_feat', '\\t', 'accuracy_score')\n",
    "\n",
    "# перебираем разные комбинации в цикле\n",
    "for depth in range(1, 6):    \n",
    "    for test_max_features in [1, 2, 3, 4, 'sqrt', 'log2']:\n",
    "        \n",
    "        model = DecisionTreeClassifier(\n",
    "            random_state=12345, \n",
    "            max_depth=depth,\n",
    "            max_features=test_max_features\n",
    "        )\n",
    "        \n",
    "        # обучаем модель на тренировочных данных\n",
    "        model.fit(features_train, target_train)\n",
    "        \n",
    "        # оцениваем качество модели на валидационной выборке\n",
    "        predictions = model.predict(features_valid)\n",
    "        result = accuracy_score(target_valid, predictions)\n",
    "        print(depth,'\\t', test_max_features, '\\t', result)\n",
    "        \n",
    "        # сохраняем лучшую на данный момент модель и ее показатели\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            desision_tree_best_model = model\n",
    "            best_max_features=test_max_features\n",
    "            best_depth = depth\n",
    "    print()\n",
    "\n",
    "print('--------------------------------------------------')\n",
    "print('best results:')\n",
    "print(best_depth,'\\t', best_max_features, '\\t', best_result)\n",
    "\n",
    "print(f'best model: {desision_tree_best_model}')\n",
    "\n",
    "# если доля правильных ответов превысит 0,75, сохраним нашу модель в списке лучших \n",
    "if best_result >= 0.75:\n",
    "    best_models.append([desision_tree_best_model, best_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность дерева решений превысила порог в 0.75. \n",
    "\n",
    "Значения  гиперпараметров: \n",
    "- глубина – 5, \n",
    "- количество учитываемых при разбиении характеристик – 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификации методом случайного леса попробуем различные комбинации следующих параметров: \n",
    "- количество деревьев в лесу,  \n",
    "- максимальная глубина деревьев, \n",
    "- количество характеристик, которые учитываются при поиске лучшего разбиения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estim depth \t max_feat \t accuracy_score\n",
      "50 \t 1 \t 1 \t 0.7340590979782271\n",
      "50 \t 1 \t 2 \t 0.7542768273716952\n",
      "50 \t 1 \t 3 \t 0.7480559875583204\n",
      "50 \t 1 \t 4 \t 0.7387247278382582\n",
      "50 \t 1 \t sqrt \t 0.7542768273716952\n",
      "50 \t 1 \t log2 \t 0.7542768273716952\n",
      "50 \t 2 \t 1 \t 0.7744945567651633\n",
      "50 \t 2 \t 2 \t 0.7947122861586314\n",
      "50 \t 2 \t 3 \t 0.7838258164852255\n",
      "50 \t 2 \t 4 \t 0.7822706065318819\n",
      "50 \t 2 \t sqrt \t 0.7947122861586314\n",
      "50 \t 2 \t log2 \t 0.7947122861586314\n",
      "50 \t 3 \t 1 \t 0.7962674961119751\n",
      "50 \t 3 \t 2 \t 0.7947122861586314\n",
      "50 \t 3 \t 3 \t 0.7978227060653188\n",
      "50 \t 3 \t 4 \t 0.7931570762052877\n",
      "50 \t 3 \t sqrt \t 0.7947122861586314\n",
      "50 \t 3 \t log2 \t 0.7947122861586314\n",
      "50 \t 4 \t 1 \t 0.7993779160186625\n",
      "50 \t 4 \t 2 \t 0.7978227060653188\n",
      "50 \t 4 \t 3 \t 0.7993779160186625\n",
      "50 \t 4 \t 4 \t 0.8009331259720062\n",
      "50 \t 4 \t sqrt \t 0.7978227060653188\n",
      "50 \t 4 \t log2 \t 0.7978227060653188\n",
      "50 \t 5 \t 1 \t 0.8055987558320373\n",
      "50 \t 5 \t 2 \t 0.8009331259720062\n",
      "50 \t 5 \t 3 \t 0.807153965785381\n",
      "50 \t 5 \t 4 \t 0.8055987558320373\n",
      "50 \t 5 \t sqrt \t 0.8009331259720062\n",
      "50 \t 5 \t log2 \t 0.8009331259720062\n",
      "\n",
      "60 \t 1 \t 1 \t 0.7293934681181959\n",
      "60 \t 1 \t 2 \t 0.7542768273716952\n",
      "60 \t 1 \t 3 \t 0.7480559875583204\n",
      "60 \t 1 \t 4 \t 0.7387247278382582\n",
      "60 \t 1 \t sqrt \t 0.7542768273716952\n",
      "60 \t 1 \t log2 \t 0.7542768273716952\n",
      "60 \t 2 \t 1 \t 0.7729393468118196\n",
      "60 \t 2 \t 2 \t 0.7947122861586314\n",
      "60 \t 2 \t 3 \t 0.7838258164852255\n",
      "60 \t 2 \t 4 \t 0.7807153965785381\n",
      "60 \t 2 \t sqrt \t 0.7947122861586314\n",
      "60 \t 2 \t log2 \t 0.7947122861586314\n",
      "60 \t 3 \t 1 \t 0.7962674961119751\n",
      "60 \t 3 \t 2 \t 0.7962674961119751\n",
      "60 \t 3 \t 3 \t 0.7947122861586314\n",
      "60 \t 3 \t 4 \t 0.7916018662519441\n",
      "60 \t 3 \t sqrt \t 0.7962674961119751\n",
      "60 \t 3 \t log2 \t 0.7962674961119751\n",
      "60 \t 4 \t 1 \t 0.7962674961119751\n",
      "60 \t 4 \t 2 \t 0.7993779160186625\n",
      "60 \t 4 \t 3 \t 0.7978227060653188\n",
      "60 \t 4 \t 4 \t 0.7962674961119751\n",
      "60 \t 4 \t sqrt \t 0.7993779160186625\n",
      "60 \t 4 \t log2 \t 0.7993779160186625\n",
      "60 \t 5 \t 1 \t 0.8009331259720062\n",
      "60 \t 5 \t 2 \t 0.7993779160186625\n",
      "60 \t 5 \t 3 \t 0.80248833592535\n",
      "60 \t 5 \t 4 \t 0.8133748055987559\n",
      "60 \t 5 \t sqrt \t 0.7993779160186625\n",
      "60 \t 5 \t log2 \t 0.7993779160186625\n",
      "\n",
      "70 \t 1 \t 1 \t 0.7309486780715396\n",
      "70 \t 1 \t 2 \t 0.7542768273716952\n",
      "70 \t 1 \t 3 \t 0.7480559875583204\n",
      "70 \t 1 \t 4 \t 0.7387247278382582\n",
      "70 \t 1 \t sqrt \t 0.7542768273716952\n",
      "70 \t 1 \t log2 \t 0.7542768273716952\n",
      "70 \t 2 \t 1 \t 0.7682737169517885\n",
      "70 \t 2 \t 2 \t 0.7884914463452566\n",
      "70 \t 2 \t 3 \t 0.7869362363919129\n",
      "70 \t 2 \t 4 \t 0.7807153965785381\n",
      "70 \t 2 \t sqrt \t 0.7884914463452566\n",
      "70 \t 2 \t log2 \t 0.7884914463452566\n",
      "70 \t 3 \t 1 \t 0.7962674961119751\n",
      "70 \t 3 \t 2 \t 0.7978227060653188\n",
      "70 \t 3 \t 3 \t 0.7947122861586314\n",
      "70 \t 3 \t 4 \t 0.7900466562986003\n",
      "70 \t 3 \t sqrt \t 0.7978227060653188\n",
      "70 \t 3 \t log2 \t 0.7978227060653188\n",
      "70 \t 4 \t 1 \t 0.7993779160186625\n",
      "70 \t 4 \t 2 \t 0.8009331259720062\n",
      "70 \t 4 \t 3 \t 0.7978227060653188\n",
      "70 \t 4 \t 4 \t 0.80248833592535\n",
      "70 \t 4 \t sqrt \t 0.8009331259720062\n",
      "70 \t 4 \t log2 \t 0.8009331259720062\n",
      "70 \t 5 \t 1 \t 0.8009331259720062\n",
      "70 \t 5 \t 2 \t 0.8009331259720062\n",
      "70 \t 5 \t 3 \t 0.7978227060653188\n",
      "70 \t 5 \t 4 \t 0.8040435458786936\n",
      "70 \t 5 \t sqrt \t 0.8009331259720062\n",
      "70 \t 5 \t log2 \t 0.8009331259720062\n",
      "\n",
      "80 \t 1 \t 1 \t 0.7340590979782271\n",
      "80 \t 1 \t 2 \t 0.7325038880248833\n",
      "80 \t 1 \t 3 \t 0.7465007776049767\n",
      "80 \t 1 \t 4 \t 0.7387247278382582\n",
      "80 \t 1 \t sqrt \t 0.7325038880248833\n",
      "80 \t 1 \t log2 \t 0.7325038880248833\n",
      "80 \t 2 \t 1 \t 0.7651632970451011\n",
      "80 \t 2 \t 2 \t 0.7869362363919129\n",
      "80 \t 2 \t 3 \t 0.7822706065318819\n",
      "80 \t 2 \t 4 \t 0.7807153965785381\n",
      "80 \t 2 \t sqrt \t 0.7869362363919129\n",
      "80 \t 2 \t log2 \t 0.7869362363919129\n",
      "80 \t 3 \t 1 \t 0.7931570762052877\n",
      "80 \t 3 \t 2 \t 0.7947122861586314\n",
      "80 \t 3 \t 3 \t 0.7931570762052877\n",
      "80 \t 3 \t 4 \t 0.7884914463452566\n",
      "80 \t 3 \t sqrt \t 0.7947122861586314\n",
      "80 \t 3 \t log2 \t 0.7947122861586314\n",
      "80 \t 4 \t 1 \t 0.7947122861586314\n",
      "80 \t 4 \t 2 \t 0.7978227060653188\n",
      "80 \t 4 \t 3 \t 0.7962674961119751\n",
      "80 \t 4 \t 4 \t 0.8040435458786936\n",
      "80 \t 4 \t sqrt \t 0.7978227060653188\n",
      "80 \t 4 \t log2 \t 0.7978227060653188\n",
      "80 \t 5 \t 1 \t 0.80248833592535\n",
      "80 \t 5 \t 2 \t 0.8009331259720062\n",
      "80 \t 5 \t 3 \t 0.8040435458786936\n",
      "80 \t 5 \t 4 \t 0.8040435458786936\n",
      "80 \t 5 \t sqrt \t 0.8009331259720062\n",
      "80 \t 5 \t log2 \t 0.8009331259720062\n",
      "\n",
      "90 \t 1 \t 1 \t 0.7325038880248833\n",
      "90 \t 1 \t 2 \t 0.7325038880248833\n",
      "90 \t 1 \t 3 \t 0.744945567651633\n",
      "90 \t 1 \t 4 \t 0.7387247278382582\n",
      "90 \t 1 \t sqrt \t 0.7325038880248833\n",
      "90 \t 1 \t log2 \t 0.7325038880248833\n",
      "90 \t 2 \t 1 \t 0.7651632970451011\n",
      "90 \t 2 \t 2 \t 0.7853810264385692\n",
      "90 \t 2 \t 3 \t 0.7822706065318819\n",
      "90 \t 2 \t 4 \t 0.7807153965785381\n",
      "90 \t 2 \t sqrt \t 0.7853810264385692\n",
      "90 \t 2 \t log2 \t 0.7853810264385692\n",
      "90 \t 3 \t 1 \t 0.7978227060653188\n",
      "90 \t 3 \t 2 \t 0.7962674961119751\n",
      "90 \t 3 \t 3 \t 0.7916018662519441\n",
      "90 \t 3 \t 4 \t 0.7900466562986003\n",
      "90 \t 3 \t sqrt \t 0.7962674961119751\n",
      "90 \t 3 \t log2 \t 0.7962674961119751\n",
      "90 \t 4 \t 1 \t 0.7947122861586314\n",
      "90 \t 4 \t 2 \t 0.7931570762052877\n",
      "90 \t 4 \t 3 \t 0.7962674961119751\n",
      "90 \t 4 \t 4 \t 0.8009331259720062\n",
      "90 \t 4 \t sqrt \t 0.7931570762052877\n",
      "90 \t 4 \t log2 \t 0.7931570762052877\n",
      "90 \t 5 \t 1 \t 0.8040435458786936\n",
      "90 \t 5 \t 2 \t 0.8009331259720062\n",
      "90 \t 5 \t 3 \t 0.8040435458786936\n",
      "90 \t 5 \t 4 \t 0.8040435458786936\n",
      "90 \t 5 \t sqrt \t 0.8009331259720062\n",
      "90 \t 5 \t log2 \t 0.8009331259720062\n",
      "\n",
      "100 \t 1 \t 1 \t 0.7356143079315708\n",
      "100 \t 1 \t 2 \t 0.7325038880248833\n",
      "100 \t 1 \t 3 \t 0.7465007776049767\n",
      "100 \t 1 \t 4 \t 0.7387247278382582\n",
      "100 \t 1 \t sqrt \t 0.7325038880248833\n",
      "100 \t 1 \t log2 \t 0.7325038880248833\n",
      "100 \t 2 \t 1 \t 0.7729393468118196\n",
      "100 \t 2 \t 2 \t 0.7869362363919129\n",
      "100 \t 2 \t 3 \t 0.7838258164852255\n",
      "100 \t 2 \t 4 \t 0.7807153965785381\n",
      "100 \t 2 \t sqrt \t 0.7869362363919129\n",
      "100 \t 2 \t log2 \t 0.7869362363919129\n",
      "100 \t 3 \t 1 \t 0.7962674961119751\n",
      "100 \t 3 \t 2 \t 0.7962674961119751\n",
      "100 \t 3 \t 3 \t 0.7947122861586314\n",
      "100 \t 3 \t 4 \t 0.7900466562986003\n",
      "100 \t 3 \t sqrt \t 0.7962674961119751\n",
      "100 \t 3 \t log2 \t 0.7962674961119751\n",
      "100 \t 4 \t 1 \t 0.7962674961119751\n",
      "100 \t 4 \t 2 \t 0.7947122861586314\n",
      "100 \t 4 \t 3 \t 0.7978227060653188\n",
      "100 \t 4 \t 4 \t 0.8009331259720062\n",
      "100 \t 4 \t sqrt \t 0.7947122861586314\n",
      "100 \t 4 \t log2 \t 0.7947122861586314\n",
      "100 \t 5 \t 1 \t 0.8055987558320373\n",
      "100 \t 5 \t 2 \t 0.7993779160186625\n",
      "100 \t 5 \t 3 \t 0.807153965785381\n",
      "100 \t 5 \t 4 \t 0.8087091757387247\n",
      "100 \t 5 \t sqrt \t 0.7993779160186625\n",
      "100 \t 5 \t log2 \t 0.7993779160186625\n",
      "\n",
      "--------------------------------------------------\n",
      "best results:\n",
      "60 \t 5 \t 4 \t 0.8133748055987559\n",
      "best model: RandomForestClassifier(max_depth=5, max_features=4, n_estimators=60,\n",
      "                       random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "# создаем переменные для лучшей на текущий момент модели и ее точности\n",
    "random_forest_best_model = None\n",
    "best_result = 0\n",
    "\n",
    "print('n_estim', 'depth', '\\t', 'max_feat', '\\t', 'accuracy_score')\n",
    "\n",
    "# перебираем разные комбинации в цикле\n",
    "for estimators in range(50, 101, 10):\n",
    "    for depth in range(1, 6):\n",
    "        for test_max_features in [1, 2, 3, 4, 'sqrt', 'log2']:\n",
    "            \n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators=estimators,\n",
    "                max_depth=depth,\n",
    "                max_features=test_max_features,\n",
    "                random_state=12345\n",
    "            )\n",
    "            \n",
    "            # обучаем модель на тренировочных данных\n",
    "            model.fit(features_train, target_train)\n",
    "            \n",
    "            # оцениваем качество модели на валидационной выборке\n",
    "            predictions = model.predict(features_valid)\n",
    "            result = accuracy_score(target_valid, predictions)\n",
    "            print(\n",
    "                estimators,'\\t',  \n",
    "                depth,'\\t', \n",
    "                test_max_features, '\\t',  \n",
    "                result\n",
    "            )   \n",
    "            # сохраняем лучшую на данный момент модель и ее показатели\n",
    "            if result > best_result:\n",
    "                best_result = result\n",
    "                random_forest_best_model = model\n",
    "                best_n_estimarots=estimators\n",
    "                best_depth = depth\n",
    "                best_max_features = test_max_features\n",
    "                \n",
    "    print()\n",
    "print('--------------------------------------------------')\n",
    "print('best results:')\n",
    "print(best_n_estimarots,'\\t', best_depth,'\\t', best_max_features, '\\t', best_result)\n",
    "\n",
    "\n",
    "print(f'best model: {random_forest_best_model}')\n",
    "\n",
    "# если доля правильных ответов превысит 0,75, сохраним нашу модель в списке лучших \n",
    "if best_result >= 0.75:\n",
    "    best_models.append([random_forest_best_model, best_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность случайного леса превысила порог с 0.75. \n",
    "\n",
    "Значения  гиперпараметров: \t\n",
    "- количество деревьев в лесу - 60\n",
    "- максимальная глубина деревьев - 5\n",
    "- количество характеристик, которые учитываются при поиске лучшего разбиения - 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификации методом логистической регрессии попробуем различные комбинации следующих параметров: \n",
    "- несколько вариантов алгоритмов для решения задачи оптимизации\n",
    "- несколько вариантов максимального числа итераций для алгоритма\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver \t max_iter \t accuracy_score\n",
      "lbfgs \t 500 \t 0.7387247278382582\n",
      "lbfgs \t 600 \t 0.7387247278382582\n",
      "lbfgs \t 700 \t 0.7387247278382582\n",
      "lbfgs \t 800 \t 0.7387247278382582\n",
      "lbfgs \t 900 \t 0.7387247278382582\n",
      "lbfgs \t 1000 \t 0.7387247278382582\n",
      "\n",
      "liblinear \t 500 \t 0.71850699844479\n",
      "liblinear \t 600 \t 0.71850699844479\n",
      "liblinear \t 700 \t 0.71850699844479\n",
      "liblinear \t 800 \t 0.71850699844479\n",
      "liblinear \t 900 \t 0.71850699844479\n",
      "liblinear \t 1000 \t 0.71850699844479\n",
      "\n",
      "newton-cg \t 500 \t 0.7387247278382582\n",
      "newton-cg \t 600 \t 0.7387247278382582\n",
      "newton-cg \t 700 \t 0.7387247278382582\n",
      "newton-cg \t 800 \t 0.7387247278382582\n",
      "newton-cg \t 900 \t 0.7387247278382582\n",
      "newton-cg \t 1000 \t 0.7387247278382582\n",
      "\n",
      "--------------------------------------------------\n",
      "best results:\n",
      "lbfgs \t 500 \t 0.7387247278382582\n",
      "best model: LogisticRegression(max_iter=500, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "# создаем переменные для лучшей на текущий момент модели и ее точности\n",
    "logistic_regression_best_model = None\n",
    "best_result = 0\n",
    "\n",
    "print('solver','\\t','max_iter','\\t', 'accuracy_score')\n",
    "\n",
    "# перебираем разные комбинации в цикле\n",
    "for test_solver in ['lbfgs', 'liblinear', 'newton-cg']:\n",
    "    for test_max_iter in range(500, 1001, 100):\n",
    "        model = LogisticRegression(\n",
    "            solver=test_solver,\n",
    "            max_iter=test_max_iter,\n",
    "            random_state=12345\n",
    "        )\n",
    "        \n",
    "        # обучаем модель на тренировочных данных\n",
    "        model.fit(features_train, target_train)\n",
    "        \n",
    "        # оцениваем качество модели на валидационной выборке\n",
    "        predictions = model.predict(features_valid)\n",
    "        result = accuracy_score(target_valid, predictions)\n",
    "        print(\n",
    "            test_solver,'\\t', \n",
    "            test_max_iter, '\\t', \n",
    "            result\n",
    "            )\n",
    "        \n",
    "        # сохраняем лучшую на данный момент модель и ее показатели\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            logistic_regression_best_model = model\n",
    "            best_solvers = test_solver\n",
    "            best_max_iter = test_max_iter\n",
    "                        \n",
    "    print()\n",
    "print('--------------------------------------------------')\n",
    "print('best results:')\n",
    "print(best_solvers,'\\t', best_max_iter, '\\t', best_result)\n",
    "\n",
    "\n",
    "print(f'best model: {logistic_regression_best_model}')\n",
    "\n",
    "# если доля правильных ответов превысит 0,75, сохраним нашу модель в списке лучших \n",
    "if best_result >= 0.75:\n",
    "    best_models.append([logistic_regression_best_model, best_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная достигнутая точность модели логистической регрессии не превысила заданного порога в 0,75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дерево решений для регрессии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания дерева решений для регрессии в задаче классификации можно трактовать как вероятность попадания в тот или иной класс. Применим к предсказаниям операцию округления и так получим разделение на классы. \n",
    "\n",
    "Попробуем различные комбинации следующих параметров: \n",
    "- функция, измеряющая качество разбиения\n",
    "- максимальная глубина деревьев, \n",
    "- количество характеристик, которые учитываются при поиске лучшего разбиения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion    max_depth max_features \t accuracy_score\n",
      "friedman_mse \t 1 \t 1 \t 0.7527216174183515\n",
      "friedman_mse \t 1 \t 2 \t 0.7527216174183515\n",
      "friedman_mse \t 1 \t 3 \t 0.7402799377916018\n",
      "friedman_mse \t 1 \t 4 \t 0.7402799377916018\n",
      "friedman_mse \t 1 \t auto \t 0.7402799377916018\n",
      "friedman_mse \t 1 \t sqrt \t 0.7527216174183515\n",
      "friedman_mse \t 1 \t log2 \t 0.7527216174183515\n",
      "\n",
      "friedman_mse \t 2 \t 1 \t 0.7807153965785381\n",
      "friedman_mse \t 2 \t 2 \t 0.7527216174183515\n",
      "friedman_mse \t 2 \t 3 \t 0.7822706065318819\n",
      "friedman_mse \t 2 \t 4 \t 0.7729393468118196\n",
      "friedman_mse \t 2 \t auto \t 0.7729393468118196\n",
      "friedman_mse \t 2 \t sqrt \t 0.7527216174183515\n",
      "friedman_mse \t 2 \t log2 \t 0.7527216174183515\n",
      "\n",
      "friedman_mse \t 3 \t 1 \t 0.7807153965785381\n",
      "friedman_mse \t 3 \t 2 \t 0.7744945567651633\n",
      "friedman_mse \t 3 \t 3 \t 0.7869362363919129\n",
      "friedman_mse \t 3 \t 4 \t 0.7776049766718507\n",
      "friedman_mse \t 3 \t auto \t 0.7776049766718507\n",
      "friedman_mse \t 3 \t sqrt \t 0.7744945567651633\n",
      "friedman_mse \t 3 \t log2 \t 0.7744945567651633\n",
      "\n",
      "friedman_mse \t 4 \t 1 \t 0.7807153965785381\n",
      "friedman_mse \t 4 \t 2 \t 0.776049766718507\n",
      "friedman_mse \t 4 \t 3 \t 0.7667185069984448\n",
      "friedman_mse \t 4 \t 4 \t 0.7542768273716952\n",
      "friedman_mse \t 4 \t auto \t 0.7542768273716952\n",
      "friedman_mse \t 4 \t sqrt \t 0.776049766718507\n",
      "friedman_mse \t 4 \t log2 \t 0.776049766718507\n",
      "\n",
      "friedman_mse \t 5 \t 1 \t 0.7884914463452566\n",
      "friedman_mse \t 5 \t 2 \t 0.7822706065318819\n",
      "friedman_mse \t 5 \t 3 \t 0.7931570762052877\n",
      "friedman_mse \t 5 \t 4 \t 0.7853810264385692\n",
      "friedman_mse \t 5 \t auto \t 0.7853810264385692\n",
      "friedman_mse \t 5 \t sqrt \t 0.7822706065318819\n",
      "friedman_mse \t 5 \t log2 \t 0.7822706065318819\n",
      "\n",
      "poisson \t 1 \t 1 \t 0.7013996889580093\n",
      "poisson \t 1 \t 2 \t 0.7013996889580093\n",
      "poisson \t 1 \t 3 \t 0.7013996889580093\n",
      "poisson \t 1 \t 4 \t 0.7076205287713841\n",
      "poisson \t 1 \t auto \t 0.7076205287713841\n",
      "poisson \t 1 \t sqrt \t 0.7013996889580093\n",
      "poisson \t 1 \t log2 \t 0.7013996889580093\n",
      "\n",
      "poisson \t 2 \t 1 \t 0.713841368584759\n",
      "poisson \t 2 \t 2 \t 0.7060653188180405\n",
      "poisson \t 2 \t 3 \t 0.7169517884914464\n",
      "poisson \t 2 \t 4 \t 0.7216174183514774\n",
      "poisson \t 2 \t auto \t 0.7216174183514774\n",
      "poisson \t 2 \t sqrt \t 0.7060653188180405\n",
      "poisson \t 2 \t log2 \t 0.7060653188180405\n",
      "\n",
      "poisson \t 3 \t 1 \t 0.7122861586314152\n",
      "poisson \t 3 \t 2 \t 0.7200622083981337\n",
      "poisson \t 3 \t 3 \t 0.7293934681181959\n",
      "poisson \t 3 \t 4 \t 0.7340590979782271\n",
      "poisson \t 3 \t auto \t 0.7340590979782271\n",
      "poisson \t 3 \t sqrt \t 0.7200622083981337\n",
      "poisson \t 3 \t log2 \t 0.7200622083981337\n",
      "\n",
      "poisson \t 4 \t 1 \t 0.7262830482115086\n",
      "poisson \t 4 \t 2 \t 0.7325038880248833\n",
      "poisson \t 4 \t 3 \t 0.7278382581648523\n",
      "poisson \t 4 \t 4 \t 0.7325038880248833\n",
      "poisson \t 4 \t auto \t 0.7325038880248833\n",
      "poisson \t 4 \t sqrt \t 0.7325038880248833\n",
      "poisson \t 4 \t log2 \t 0.7325038880248833\n",
      "\n",
      "poisson \t 5 \t 1 \t 0.7418351477449455\n",
      "poisson \t 5 \t 2 \t 0.7371695178849145\n",
      "poisson \t 5 \t 3 \t 0.7309486780715396\n",
      "poisson \t 5 \t 4 \t 0.7356143079315708\n",
      "poisson \t 5 \t auto \t 0.7356143079315708\n",
      "poisson \t 5 \t sqrt \t 0.7371695178849145\n",
      "poisson \t 5 \t log2 \t 0.7371695178849145\n",
      "\n",
      "--------------------------------------------------\n",
      "best results:\n",
      "friedman_mse \t 5 \t 3 \t 0.7931570762052877\n",
      "best model: DecisionTreeRegressor(criterion='friedman_mse', max_depth=5, max_features=3,\n",
      "                      random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "# создаем переменные для лучшей на текущий момент модели и ее точности\n",
    "decision_tree_regressor_best_model = None\n",
    "best_result = 0\n",
    "\n",
    "print('criterion', '  ', 'max_depth', 'max_features', '\\t', 'accuracy_score')\n",
    "\n",
    "# перебираем разные комбинации в цикле\n",
    "for test_criterion in [ 'friedman_mse', 'poisson']:\n",
    "    for depth in range(1, 6):\n",
    "        for test_max_features in [1, 2, 3, 4, 'auto', 'sqrt', 'log2']:\n",
    "            model = DecisionTreeRegressor(\n",
    "                criterion=test_criterion,\n",
    "                max_depth=depth,\n",
    "                max_features=test_max_features,\n",
    "                random_state=12345\n",
    "            )\n",
    "            \n",
    "            # обучаем модель на тренировочных данных\n",
    "            model.fit(features_train, target_train)\n",
    "            \n",
    "            # оцениваем качество модели на валидационной выборке\n",
    "            predictions = model.predict(features_valid).round()\n",
    "            result = accuracy_score(target_valid, predictions)\n",
    "            print(\n",
    "                test_criterion,'\\t', \n",
    "                depth, '\\t', \n",
    "                test_max_features, '\\t', \n",
    "                result\n",
    "                )\n",
    "            # сохраняем лучшую на данный момент модель и ее показатели\n",
    "            if result > best_result:\n",
    "                best_result = result\n",
    "                decision_tree_regressor_best_model = model\n",
    "                best_criterion = test_criterion\n",
    "                best_max_depth = depth\n",
    "                best_max_features = test_max_features\n",
    "                        \n",
    "        print()\n",
    "print('--------------------------------------------------')\n",
    "print('best results:')\n",
    "print(best_criterion,'\\t', best_max_depth, '\\t', best_max_features, '\\t', best_result)\n",
    "\n",
    "\n",
    "print(f'best model: {decision_tree_regressor_best_model}')\n",
    "\n",
    "# если доля правильных ответов превысит 0,75, сохраним нашу модель в списке лучших \n",
    "if best_result >= 0.75:\n",
    "    best_models.append([decision_tree_regressor_best_model, best_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность дерева решений для регрессии превысила порог с 0.75.\n",
    "\n",
    "Значения  гиперпараметров: \t\n",
    "- функция, измеряющая качество разбиения - friedman_mse\n",
    "- максимальная глубина деревьев - 5\n",
    "- количество характеристик, которые учитываются при поиске лучшего разбиения - 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Случайный лес для регресcии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания случайного леса для регрессии в задаче классификации также можно трактовать как вероятность попадания в тот или иной класс. \n",
    "\n",
    "Здесь тоже применим к предсказаниям операцию округления и так получим разделение на классы. \n",
    "\n",
    "Попробуем различные комбинации следующих параметров: \n",
    "- количество деревьев в лесу, \n",
    "- функция, измеряющая качество разбиения, \n",
    "- максимальная глубина деревьев, \n",
    "- количество характеристик, которые учитываются при поиске лучшего разбиения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estim    criter \t depth \t max_feat   accuracy_score\n",
      "50 \t friedman_mse \t 1 \t 1 \t 0.7340590979782271\n",
      "50 \t friedman_mse \t 1 \t 2 \t 0.7542768273716952\n",
      "50 \t friedman_mse \t 1 \t 3 \t 0.7480559875583204\n",
      "50 \t friedman_mse \t 1 \t 4 \t 0.7387247278382582\n",
      "50 \t friedman_mse \t 1 \t sqrt \t 0.7542768273716952\n",
      "50 \t friedman_mse \t 1 \t log2 \t 0.7542768273716952\n",
      "50 \t friedman_mse \t 2 \t 1 \t 0.7744945567651633\n",
      "50 \t friedman_mse \t 2 \t 2 \t 0.7947122861586314\n",
      "50 \t friedman_mse \t 2 \t 3 \t 0.7838258164852255\n",
      "50 \t friedman_mse \t 2 \t 4 \t 0.7822706065318819\n",
      "50 \t friedman_mse \t 2 \t sqrt \t 0.7947122861586314\n",
      "50 \t friedman_mse \t 2 \t log2 \t 0.7947122861586314\n",
      "50 \t friedman_mse \t 3 \t 1 \t 0.7962674961119751\n",
      "50 \t friedman_mse \t 3 \t 2 \t 0.7947122861586314\n",
      "50 \t friedman_mse \t 3 \t 3 \t 0.7978227060653188\n",
      "50 \t friedman_mse \t 3 \t 4 \t 0.7931570762052877\n",
      "50 \t friedman_mse \t 3 \t sqrt \t 0.7947122861586314\n",
      "50 \t friedman_mse \t 3 \t log2 \t 0.7947122861586314\n",
      "50 \t friedman_mse \t 4 \t 1 \t 0.7993779160186625\n",
      "50 \t friedman_mse \t 4 \t 2 \t 0.7978227060653188\n",
      "50 \t friedman_mse \t 4 \t 3 \t 0.7993779160186625\n",
      "50 \t friedman_mse \t 4 \t 4 \t 0.8009331259720062\n",
      "50 \t friedman_mse \t 4 \t sqrt \t 0.7978227060653188\n",
      "50 \t friedman_mse \t 4 \t log2 \t 0.7978227060653188\n",
      "50 \t friedman_mse \t 5 \t 1 \t 0.8055987558320373\n",
      "50 \t friedman_mse \t 5 \t 2 \t 0.8009331259720062\n",
      "50 \t friedman_mse \t 5 \t 3 \t 0.807153965785381\n",
      "50 \t friedman_mse \t 5 \t 4 \t 0.8055987558320373\n",
      "50 \t friedman_mse \t 5 \t sqrt \t 0.8009331259720062\n",
      "50 \t friedman_mse \t 5 \t log2 \t 0.8009331259720062\n",
      "50 \t poisson \t 1 \t 1 \t 0.7060653188180405\n",
      "50 \t poisson \t 1 \t 2 \t 0.7091757387247278\n",
      "50 \t poisson \t 1 \t 3 \t 0.7091757387247278\n",
      "50 \t poisson \t 1 \t 4 \t 0.7060653188180405\n",
      "50 \t poisson \t 1 \t sqrt \t 0.7091757387247278\n",
      "50 \t poisson \t 1 \t log2 \t 0.7091757387247278\n",
      "50 \t poisson \t 2 \t 1 \t 0.7325038880248833\n",
      "50 \t poisson \t 2 \t 2 \t 0.7169517884914464\n",
      "50 \t poisson \t 2 \t 3 \t 0.7309486780715396\n",
      "50 \t poisson \t 2 \t 4 \t 0.7309486780715396\n",
      "50 \t poisson \t 2 \t sqrt \t 0.7169517884914464\n",
      "50 \t poisson \t 2 \t log2 \t 0.7169517884914464\n",
      "50 \t poisson \t 3 \t 1 \t 0.7387247278382582\n",
      "50 \t poisson \t 3 \t 2 \t 0.7356143079315708\n",
      "50 \t poisson \t 3 \t 3 \t 0.7309486780715396\n",
      "50 \t poisson \t 3 \t 4 \t 0.7325038880248833\n",
      "50 \t poisson \t 3 \t sqrt \t 0.7356143079315708\n",
      "50 \t poisson \t 3 \t log2 \t 0.7356143079315708\n",
      "50 \t poisson \t 4 \t 1 \t 0.7387247278382582\n",
      "50 \t poisson \t 4 \t 2 \t 0.7402799377916018\n",
      "50 \t poisson \t 4 \t 3 \t 0.7356143079315708\n",
      "50 \t poisson \t 4 \t 4 \t 0.7309486780715396\n",
      "50 \t poisson \t 4 \t sqrt \t 0.7402799377916018\n",
      "50 \t poisson \t 4 \t log2 \t 0.7402799377916018\n",
      "50 \t poisson \t 5 \t 1 \t 0.7433903576982893\n",
      "50 \t poisson \t 5 \t 2 \t 0.7387247278382582\n",
      "50 \t poisson \t 5 \t 3 \t 0.7387247278382582\n",
      "50 \t poisson \t 5 \t 4 \t 0.7402799377916018\n",
      "50 \t poisson \t 5 \t sqrt \t 0.7387247278382582\n",
      "50 \t poisson \t 5 \t log2 \t 0.7387247278382582\n",
      "\n",
      "60 \t friedman_mse \t 1 \t 1 \t 0.7293934681181959\n",
      "60 \t friedman_mse \t 1 \t 2 \t 0.7542768273716952\n",
      "60 \t friedman_mse \t 1 \t 3 \t 0.7480559875583204\n",
      "60 \t friedman_mse \t 1 \t 4 \t 0.7387247278382582\n",
      "60 \t friedman_mse \t 1 \t sqrt \t 0.7542768273716952\n",
      "60 \t friedman_mse \t 1 \t log2 \t 0.7542768273716952\n",
      "60 \t friedman_mse \t 2 \t 1 \t 0.7729393468118196\n",
      "60 \t friedman_mse \t 2 \t 2 \t 0.7947122861586314\n",
      "60 \t friedman_mse \t 2 \t 3 \t 0.7838258164852255\n",
      "60 \t friedman_mse \t 2 \t 4 \t 0.7807153965785381\n",
      "60 \t friedman_mse \t 2 \t sqrt \t 0.7947122861586314\n",
      "60 \t friedman_mse \t 2 \t log2 \t 0.7947122861586314\n",
      "60 \t friedman_mse \t 3 \t 1 \t 0.7962674961119751\n",
      "60 \t friedman_mse \t 3 \t 2 \t 0.7962674961119751\n",
      "60 \t friedman_mse \t 3 \t 3 \t 0.7947122861586314\n",
      "60 \t friedman_mse \t 3 \t 4 \t 0.7916018662519441\n",
      "60 \t friedman_mse \t 3 \t sqrt \t 0.7962674961119751\n",
      "60 \t friedman_mse \t 3 \t log2 \t 0.7962674961119751\n",
      "60 \t friedman_mse \t 4 \t 1 \t 0.7962674961119751\n",
      "60 \t friedman_mse \t 4 \t 2 \t 0.7993779160186625\n",
      "60 \t friedman_mse \t 4 \t 3 \t 0.7978227060653188\n",
      "60 \t friedman_mse \t 4 \t 4 \t 0.7962674961119751\n",
      "60 \t friedman_mse \t 4 \t sqrt \t 0.7993779160186625\n",
      "60 \t friedman_mse \t 4 \t log2 \t 0.7993779160186625\n",
      "60 \t friedman_mse \t 5 \t 1 \t 0.8009331259720062\n",
      "60 \t friedman_mse \t 5 \t 2 \t 0.7993779160186625\n",
      "60 \t friedman_mse \t 5 \t 3 \t 0.80248833592535\n",
      "60 \t friedman_mse \t 5 \t 4 \t 0.8133748055987559\n",
      "60 \t friedman_mse \t 5 \t sqrt \t 0.7993779160186625\n",
      "60 \t friedman_mse \t 5 \t log2 \t 0.7993779160186625\n",
      "60 \t poisson \t 1 \t 1 \t 0.7060653188180405\n",
      "60 \t poisson \t 1 \t 2 \t 0.7091757387247278\n",
      "60 \t poisson \t 1 \t 3 \t 0.7091757387247278\n",
      "60 \t poisson \t 1 \t 4 \t 0.7076205287713841\n",
      "60 \t poisson \t 1 \t sqrt \t 0.7091757387247278\n",
      "60 \t poisson \t 1 \t log2 \t 0.7091757387247278\n",
      "60 \t poisson \t 2 \t 1 \t 0.7325038880248833\n",
      "60 \t poisson \t 2 \t 2 \t 0.7169517884914464\n",
      "60 \t poisson \t 2 \t 3 \t 0.7309486780715396\n",
      "60 \t poisson \t 2 \t 4 \t 0.7309486780715396\n",
      "60 \t poisson \t 2 \t sqrt \t 0.7169517884914464\n",
      "60 \t poisson \t 2 \t log2 \t 0.7169517884914464\n",
      "60 \t poisson \t 3 \t 1 \t 0.7387247278382582\n",
      "60 \t poisson \t 3 \t 2 \t 0.7309486780715396\n",
      "60 \t poisson \t 3 \t 3 \t 0.7309486780715396\n",
      "60 \t poisson \t 3 \t 4 \t 0.7340590979782271\n",
      "60 \t poisson \t 3 \t sqrt \t 0.7309486780715396\n",
      "60 \t poisson \t 3 \t log2 \t 0.7309486780715396\n",
      "60 \t poisson \t 4 \t 1 \t 0.7387247278382582\n",
      "60 \t poisson \t 4 \t 2 \t 0.7402799377916018\n",
      "60 \t poisson \t 4 \t 3 \t 0.7309486780715396\n",
      "60 \t poisson \t 4 \t 4 \t 0.7325038880248833\n",
      "60 \t poisson \t 4 \t sqrt \t 0.7402799377916018\n",
      "60 \t poisson \t 4 \t log2 \t 0.7402799377916018\n",
      "60 \t poisson \t 5 \t 1 \t 0.7433903576982893\n",
      "60 \t poisson \t 5 \t 2 \t 0.7387247278382582\n",
      "60 \t poisson \t 5 \t 3 \t 0.7387247278382582\n",
      "60 \t poisson \t 5 \t 4 \t 0.7402799377916018\n",
      "60 \t poisson \t 5 \t sqrt \t 0.7387247278382582\n",
      "60 \t poisson \t 5 \t log2 \t 0.7387247278382582\n",
      "\n",
      "70 \t friedman_mse \t 1 \t 1 \t 0.7309486780715396\n",
      "70 \t friedman_mse \t 1 \t 2 \t 0.7542768273716952\n",
      "70 \t friedman_mse \t 1 \t 3 \t 0.7480559875583204\n",
      "70 \t friedman_mse \t 1 \t 4 \t 0.7387247278382582\n",
      "70 \t friedman_mse \t 1 \t sqrt \t 0.7542768273716952\n",
      "70 \t friedman_mse \t 1 \t log2 \t 0.7542768273716952\n",
      "70 \t friedman_mse \t 2 \t 1 \t 0.7682737169517885\n",
      "70 \t friedman_mse \t 2 \t 2 \t 0.7884914463452566\n",
      "70 \t friedman_mse \t 2 \t 3 \t 0.7869362363919129\n",
      "70 \t friedman_mse \t 2 \t 4 \t 0.7807153965785381\n",
      "70 \t friedman_mse \t 2 \t sqrt \t 0.7884914463452566\n",
      "70 \t friedman_mse \t 2 \t log2 \t 0.7884914463452566\n",
      "70 \t friedman_mse \t 3 \t 1 \t 0.7962674961119751\n",
      "70 \t friedman_mse \t 3 \t 2 \t 0.7978227060653188\n",
      "70 \t friedman_mse \t 3 \t 3 \t 0.7947122861586314\n",
      "70 \t friedman_mse \t 3 \t 4 \t 0.7900466562986003\n",
      "70 \t friedman_mse \t 3 \t sqrt \t 0.7978227060653188\n",
      "70 \t friedman_mse \t 3 \t log2 \t 0.7978227060653188\n",
      "70 \t friedman_mse \t 4 \t 1 \t 0.7993779160186625\n",
      "70 \t friedman_mse \t 4 \t 2 \t 0.8009331259720062\n",
      "70 \t friedman_mse \t 4 \t 3 \t 0.7978227060653188\n",
      "70 \t friedman_mse \t 4 \t 4 \t 0.80248833592535\n",
      "70 \t friedman_mse \t 4 \t sqrt \t 0.8009331259720062\n",
      "70 \t friedman_mse \t 4 \t log2 \t 0.8009331259720062\n",
      "70 \t friedman_mse \t 5 \t 1 \t 0.8009331259720062\n",
      "70 \t friedman_mse \t 5 \t 2 \t 0.8009331259720062\n",
      "70 \t friedman_mse \t 5 \t 3 \t 0.7978227060653188\n",
      "70 \t friedman_mse \t 5 \t 4 \t 0.8040435458786936\n",
      "70 \t friedman_mse \t 5 \t sqrt \t 0.8009331259720062\n",
      "70 \t friedman_mse \t 5 \t log2 \t 0.8009331259720062\n",
      "70 \t poisson \t 1 \t 1 \t 0.7060653188180405\n",
      "70 \t poisson \t 1 \t 2 \t 0.7091757387247278\n",
      "70 \t poisson \t 1 \t 3 \t 0.7091757387247278\n",
      "70 \t poisson \t 1 \t 4 \t 0.7060653188180405\n",
      "70 \t poisson \t 1 \t sqrt \t 0.7091757387247278\n",
      "70 \t poisson \t 1 \t log2 \t 0.7091757387247278\n",
      "70 \t poisson \t 2 \t 1 \t 0.7325038880248833\n",
      "70 \t poisson \t 2 \t 2 \t 0.7293934681181959\n",
      "70 \t poisson \t 2 \t 3 \t 0.7325038880248833\n",
      "70 \t poisson \t 2 \t 4 \t 0.7309486780715396\n",
      "70 \t poisson \t 2 \t sqrt \t 0.7293934681181959\n",
      "70 \t poisson \t 2 \t log2 \t 0.7293934681181959\n",
      "70 \t poisson \t 3 \t 1 \t 0.7387247278382582\n",
      "70 \t poisson \t 3 \t 2 \t 0.7309486780715396\n",
      "70 \t poisson \t 3 \t 3 \t 0.7325038880248833\n",
      "70 \t poisson \t 3 \t 4 \t 0.7340590979782271\n",
      "70 \t poisson \t 3 \t sqrt \t 0.7309486780715396\n",
      "70 \t poisson \t 3 \t log2 \t 0.7309486780715396\n",
      "70 \t poisson \t 4 \t 1 \t 0.7387247278382582\n",
      "70 \t poisson \t 4 \t 2 \t 0.7402799377916018\n",
      "70 \t poisson \t 4 \t 3 \t 0.7325038880248833\n",
      "70 \t poisson \t 4 \t 4 \t 0.7325038880248833\n",
      "70 \t poisson \t 4 \t sqrt \t 0.7402799377916018\n",
      "70 \t poisson \t 4 \t log2 \t 0.7402799377916018\n",
      "70 \t poisson \t 5 \t 1 \t 0.7418351477449455\n",
      "70 \t poisson \t 5 \t 2 \t 0.7387247278382582\n",
      "70 \t poisson \t 5 \t 3 \t 0.7387247278382582\n",
      "70 \t poisson \t 5 \t 4 \t 0.7402799377916018\n",
      "70 \t poisson \t 5 \t sqrt \t 0.7387247278382582\n",
      "70 \t poisson \t 5 \t log2 \t 0.7387247278382582\n",
      "\n",
      "80 \t friedman_mse \t 1 \t 1 \t 0.7340590979782271\n",
      "80 \t friedman_mse \t 1 \t 2 \t 0.7325038880248833\n",
      "80 \t friedman_mse \t 1 \t 3 \t 0.7465007776049767\n",
      "80 \t friedman_mse \t 1 \t 4 \t 0.7387247278382582\n",
      "80 \t friedman_mse \t 1 \t sqrt \t 0.7325038880248833\n",
      "80 \t friedman_mse \t 1 \t log2 \t 0.7325038880248833\n",
      "80 \t friedman_mse \t 2 \t 1 \t 0.7651632970451011\n",
      "80 \t friedman_mse \t 2 \t 2 \t 0.7869362363919129\n",
      "80 \t friedman_mse \t 2 \t 3 \t 0.7822706065318819\n",
      "80 \t friedman_mse \t 2 \t 4 \t 0.7807153965785381\n",
      "80 \t friedman_mse \t 2 \t sqrt \t 0.7869362363919129\n",
      "80 \t friedman_mse \t 2 \t log2 \t 0.7869362363919129\n",
      "80 \t friedman_mse \t 3 \t 1 \t 0.7931570762052877\n",
      "80 \t friedman_mse \t 3 \t 2 \t 0.7947122861586314\n",
      "80 \t friedman_mse \t 3 \t 3 \t 0.7931570762052877\n",
      "80 \t friedman_mse \t 3 \t 4 \t 0.7884914463452566\n",
      "80 \t friedman_mse \t 3 \t sqrt \t 0.7947122861586314\n",
      "80 \t friedman_mse \t 3 \t log2 \t 0.7947122861586314\n",
      "80 \t friedman_mse \t 4 \t 1 \t 0.7947122861586314\n",
      "80 \t friedman_mse \t 4 \t 2 \t 0.7978227060653188\n",
      "80 \t friedman_mse \t 4 \t 3 \t 0.7962674961119751\n",
      "80 \t friedman_mse \t 4 \t 4 \t 0.8040435458786936\n",
      "80 \t friedman_mse \t 4 \t sqrt \t 0.7978227060653188\n",
      "80 \t friedman_mse \t 4 \t log2 \t 0.7978227060653188\n",
      "80 \t friedman_mse \t 5 \t 1 \t 0.80248833592535\n",
      "80 \t friedman_mse \t 5 \t 2 \t 0.8009331259720062\n",
      "80 \t friedman_mse \t 5 \t 3 \t 0.8040435458786936\n",
      "80 \t friedman_mse \t 5 \t 4 \t 0.8040435458786936\n",
      "80 \t friedman_mse \t 5 \t sqrt \t 0.8009331259720062\n",
      "80 \t friedman_mse \t 5 \t log2 \t 0.8009331259720062\n",
      "80 \t poisson \t 1 \t 1 \t 0.7076205287713841\n",
      "80 \t poisson \t 1 \t 2 \t 0.7091757387247278\n",
      "80 \t poisson \t 1 \t 3 \t 0.7091757387247278\n",
      "80 \t poisson \t 1 \t 4 \t 0.7076205287713841\n",
      "80 \t poisson \t 1 \t sqrt \t 0.7091757387247278\n",
      "80 \t poisson \t 1 \t log2 \t 0.7091757387247278\n",
      "80 \t poisson \t 2 \t 1 \t 0.7325038880248833\n",
      "80 \t poisson \t 2 \t 2 \t 0.7325038880248833\n",
      "80 \t poisson \t 2 \t 3 \t 0.7325038880248833\n",
      "80 \t poisson \t 2 \t 4 \t 0.7340590979782271\n",
      "80 \t poisson \t 2 \t sqrt \t 0.7325038880248833\n",
      "80 \t poisson \t 2 \t log2 \t 0.7325038880248833\n",
      "80 \t poisson \t 3 \t 1 \t 0.7371695178849145\n",
      "80 \t poisson \t 3 \t 2 \t 0.7309486780715396\n",
      "80 \t poisson \t 3 \t 3 \t 0.7340590979782271\n",
      "80 \t poisson \t 3 \t 4 \t 0.7371695178849145\n",
      "80 \t poisson \t 3 \t sqrt \t 0.7309486780715396\n",
      "80 \t poisson \t 3 \t log2 \t 0.7309486780715396\n",
      "80 \t poisson \t 4 \t 1 \t 0.7387247278382582\n",
      "80 \t poisson \t 4 \t 2 \t 0.7356143079315708\n",
      "80 \t poisson \t 4 \t 3 \t 0.7325038880248833\n",
      "80 \t poisson \t 4 \t 4 \t 0.7356143079315708\n",
      "80 \t poisson \t 4 \t sqrt \t 0.7356143079315708\n",
      "80 \t poisson \t 4 \t log2 \t 0.7356143079315708\n",
      "80 \t poisson \t 5 \t 1 \t 0.7433903576982893\n",
      "80 \t poisson \t 5 \t 2 \t 0.7402799377916018\n",
      "80 \t poisson \t 5 \t 3 \t 0.7387247278382582\n",
      "80 \t poisson \t 5 \t 4 \t 0.7402799377916018\n",
      "80 \t poisson \t 5 \t sqrt \t 0.7402799377916018\n",
      "80 \t poisson \t 5 \t log2 \t 0.7402799377916018\n",
      "\n",
      "90 \t friedman_mse \t 1 \t 1 \t 0.7325038880248833\n",
      "90 \t friedman_mse \t 1 \t 2 \t 0.7325038880248833\n",
      "90 \t friedman_mse \t 1 \t 3 \t 0.744945567651633\n",
      "90 \t friedman_mse \t 1 \t 4 \t 0.7387247278382582\n",
      "90 \t friedman_mse \t 1 \t sqrt \t 0.7325038880248833\n",
      "90 \t friedman_mse \t 1 \t log2 \t 0.7325038880248833\n",
      "90 \t friedman_mse \t 2 \t 1 \t 0.7651632970451011\n",
      "90 \t friedman_mse \t 2 \t 2 \t 0.7853810264385692\n",
      "90 \t friedman_mse \t 2 \t 3 \t 0.7822706065318819\n",
      "90 \t friedman_mse \t 2 \t 4 \t 0.7807153965785381\n",
      "90 \t friedman_mse \t 2 \t sqrt \t 0.7853810264385692\n",
      "90 \t friedman_mse \t 2 \t log2 \t 0.7853810264385692\n",
      "90 \t friedman_mse \t 3 \t 1 \t 0.7978227060653188\n",
      "90 \t friedman_mse \t 3 \t 2 \t 0.7962674961119751\n",
      "90 \t friedman_mse \t 3 \t 3 \t 0.7916018662519441\n",
      "90 \t friedman_mse \t 3 \t 4 \t 0.7900466562986003\n",
      "90 \t friedman_mse \t 3 \t sqrt \t 0.7962674961119751\n",
      "90 \t friedman_mse \t 3 \t log2 \t 0.7962674961119751\n",
      "90 \t friedman_mse \t 4 \t 1 \t 0.7947122861586314\n",
      "90 \t friedman_mse \t 4 \t 2 \t 0.7931570762052877\n",
      "90 \t friedman_mse \t 4 \t 3 \t 0.7962674961119751\n",
      "90 \t friedman_mse \t 4 \t 4 \t 0.8009331259720062\n",
      "90 \t friedman_mse \t 4 \t sqrt \t 0.7931570762052877\n",
      "90 \t friedman_mse \t 4 \t log2 \t 0.7931570762052877\n",
      "90 \t friedman_mse \t 5 \t 1 \t 0.8040435458786936\n",
      "90 \t friedman_mse \t 5 \t 2 \t 0.8009331259720062\n",
      "90 \t friedman_mse \t 5 \t 3 \t 0.8040435458786936\n",
      "90 \t friedman_mse \t 5 \t 4 \t 0.8040435458786936\n",
      "90 \t friedman_mse \t 5 \t sqrt \t 0.8009331259720062\n",
      "90 \t friedman_mse \t 5 \t log2 \t 0.8009331259720062\n",
      "90 \t poisson \t 1 \t 1 \t 0.7076205287713841\n",
      "90 \t poisson \t 1 \t 2 \t 0.7091757387247278\n",
      "90 \t poisson \t 1 \t 3 \t 0.7091757387247278\n",
      "90 \t poisson \t 1 \t 4 \t 0.7076205287713841\n",
      "90 \t poisson \t 1 \t sqrt \t 0.7091757387247278\n",
      "90 \t poisson \t 1 \t log2 \t 0.7091757387247278\n",
      "90 \t poisson \t 2 \t 1 \t 0.7325038880248833\n",
      "90 \t poisson \t 2 \t 2 \t 0.7325038880248833\n",
      "90 \t poisson \t 2 \t 3 \t 0.7325038880248833\n",
      "90 \t poisson \t 2 \t 4 \t 0.7325038880248833\n",
      "90 \t poisson \t 2 \t sqrt \t 0.7325038880248833\n",
      "90 \t poisson \t 2 \t log2 \t 0.7325038880248833\n",
      "90 \t poisson \t 3 \t 1 \t 0.7356143079315708\n",
      "90 \t poisson \t 3 \t 2 \t 0.7309486780715396\n",
      "90 \t poisson \t 3 \t 3 \t 0.7325038880248833\n",
      "90 \t poisson \t 3 \t 4 \t 0.7371695178849145\n",
      "90 \t poisson \t 3 \t sqrt \t 0.7309486780715396\n",
      "90 \t poisson \t 3 \t log2 \t 0.7309486780715396\n",
      "90 \t poisson \t 4 \t 1 \t 0.7387247278382582\n",
      "90 \t poisson \t 4 \t 2 \t 0.7356143079315708\n",
      "90 \t poisson \t 4 \t 3 \t 0.7325038880248833\n",
      "90 \t poisson \t 4 \t 4 \t 0.7356143079315708\n",
      "90 \t poisson \t 4 \t sqrt \t 0.7356143079315708\n",
      "90 \t poisson \t 4 \t log2 \t 0.7356143079315708\n",
      "90 \t poisson \t 5 \t 1 \t 0.7418351477449455\n",
      "90 \t poisson \t 5 \t 2 \t 0.7402799377916018\n",
      "90 \t poisson \t 5 \t 3 \t 0.7387247278382582\n",
      "90 \t poisson \t 5 \t 4 \t 0.7402799377916018\n",
      "90 \t poisson \t 5 \t sqrt \t 0.7402799377916018\n",
      "90 \t poisson \t 5 \t log2 \t 0.7402799377916018\n",
      "\n",
      "100 \t friedman_mse \t 1 \t 1 \t 0.7356143079315708\n",
      "100 \t friedman_mse \t 1 \t 2 \t 0.7325038880248833\n",
      "100 \t friedman_mse \t 1 \t 3 \t 0.7465007776049767\n",
      "100 \t friedman_mse \t 1 \t 4 \t 0.7387247278382582\n",
      "100 \t friedman_mse \t 1 \t sqrt \t 0.7325038880248833\n",
      "100 \t friedman_mse \t 1 \t log2 \t 0.7325038880248833\n",
      "100 \t friedman_mse \t 2 \t 1 \t 0.7729393468118196\n",
      "100 \t friedman_mse \t 2 \t 2 \t 0.7869362363919129\n",
      "100 \t friedman_mse \t 2 \t 3 \t 0.7838258164852255\n",
      "100 \t friedman_mse \t 2 \t 4 \t 0.7807153965785381\n",
      "100 \t friedman_mse \t 2 \t sqrt \t 0.7869362363919129\n",
      "100 \t friedman_mse \t 2 \t log2 \t 0.7869362363919129\n",
      "100 \t friedman_mse \t 3 \t 1 \t 0.7962674961119751\n",
      "100 \t friedman_mse \t 3 \t 2 \t 0.7962674961119751\n",
      "100 \t friedman_mse \t 3 \t 3 \t 0.7947122861586314\n",
      "100 \t friedman_mse \t 3 \t 4 \t 0.7900466562986003\n",
      "100 \t friedman_mse \t 3 \t sqrt \t 0.7962674961119751\n",
      "100 \t friedman_mse \t 3 \t log2 \t 0.7962674961119751\n",
      "100 \t friedman_mse \t 4 \t 1 \t 0.7962674961119751\n",
      "100 \t friedman_mse \t 4 \t 2 \t 0.7947122861586314\n",
      "100 \t friedman_mse \t 4 \t 3 \t 0.7978227060653188\n",
      "100 \t friedman_mse \t 4 \t 4 \t 0.8009331259720062\n",
      "100 \t friedman_mse \t 4 \t sqrt \t 0.7947122861586314\n",
      "100 \t friedman_mse \t 4 \t log2 \t 0.7947122861586314\n",
      "100 \t friedman_mse \t 5 \t 1 \t 0.8055987558320373\n",
      "100 \t friedman_mse \t 5 \t 2 \t 0.7993779160186625\n",
      "100 \t friedman_mse \t 5 \t 3 \t 0.807153965785381\n",
      "100 \t friedman_mse \t 5 \t 4 \t 0.8087091757387247\n",
      "100 \t friedman_mse \t 5 \t sqrt \t 0.7993779160186625\n",
      "100 \t friedman_mse \t 5 \t log2 \t 0.7993779160186625\n",
      "100 \t poisson \t 1 \t 1 \t 0.7060653188180405\n",
      "100 \t poisson \t 1 \t 2 \t 0.7091757387247278\n",
      "100 \t poisson \t 1 \t 3 \t 0.7091757387247278\n",
      "100 \t poisson \t 1 \t 4 \t 0.7091757387247278\n",
      "100 \t poisson \t 1 \t sqrt \t 0.7091757387247278\n",
      "100 \t poisson \t 1 \t log2 \t 0.7091757387247278\n",
      "100 \t poisson \t 2 \t 1 \t 0.7325038880248833\n",
      "100 \t poisson \t 2 \t 2 \t 0.7325038880248833\n",
      "100 \t poisson \t 2 \t 3 \t 0.7325038880248833\n",
      "100 \t poisson \t 2 \t 4 \t 0.7325038880248833\n",
      "100 \t poisson \t 2 \t sqrt \t 0.7325038880248833\n",
      "100 \t poisson \t 2 \t log2 \t 0.7325038880248833\n",
      "100 \t poisson \t 3 \t 1 \t 0.7356143079315708\n",
      "100 \t poisson \t 3 \t 2 \t 0.7309486780715396\n",
      "100 \t poisson \t 3 \t 3 \t 0.7325038880248833\n",
      "100 \t poisson \t 3 \t 4 \t 0.7371695178849145\n",
      "100 \t poisson \t 3 \t sqrt \t 0.7309486780715396\n",
      "100 \t poisson \t 3 \t log2 \t 0.7309486780715396\n",
      "100 \t poisson \t 4 \t 1 \t 0.7387247278382582\n",
      "100 \t poisson \t 4 \t 2 \t 0.7402799377916018\n",
      "100 \t poisson \t 4 \t 3 \t 0.7325038880248833\n",
      "100 \t poisson \t 4 \t 4 \t 0.7356143079315708\n",
      "100 \t poisson \t 4 \t sqrt \t 0.7402799377916018\n",
      "100 \t poisson \t 4 \t log2 \t 0.7402799377916018\n",
      "100 \t poisson \t 5 \t 1 \t 0.7418351477449455\n",
      "100 \t poisson \t 5 \t 2 \t 0.7402799377916018\n",
      "100 \t poisson \t 5 \t 3 \t 0.7371695178849145\n",
      "100 \t poisson \t 5 \t 4 \t 0.7402799377916018\n",
      "100 \t poisson \t 5 \t sqrt \t 0.7402799377916018\n",
      "100 \t poisson \t 5 \t log2 \t 0.7402799377916018\n",
      "\n",
      "--------------------------------------------------\n",
      "best results:\n",
      "60 \t friedman_mse \t 5 \t 4 \t 0.8133748055987559\n",
      "best model: RandomForestRegressor(criterion='friedman_mse', max_depth=5, max_features=4,\n",
      "                      n_estimators=60, random_state=12345)\n"
     ]
    }
   ],
   "source": [
    "# создаем переменные для лучшей на текущий момент модели и ее точности\n",
    "random_forest_regressor_best_model = None\n",
    "best_result = 0\n",
    "\n",
    "print('n_estim','  ', 'criter','\\t','depth','\\t', 'max_feat', ' ', 'accuracy_score')\n",
    "\n",
    "# перебираем разные комбинации в цикле\n",
    "for estimators in range(50, 101, 10):\n",
    "    for test_criterion in ['friedman_mse', 'poisson']:\n",
    "        for depth in range(1, 6):\n",
    "            for test_max_features in [1, 2, 3, 4, 'sqrt', 'log2']:\n",
    "                model = RandomForestRegressor(\n",
    "                    n_estimators=estimators,\n",
    "                    criterion=test_criterion,\n",
    "                    max_depth=depth,\n",
    "                    max_features=test_max_features,\n",
    "                    random_state=12345\n",
    "                )\n",
    "                \n",
    "                # обучаем модель на тренировочных данных\n",
    "                model.fit(features_train, target_train)\n",
    "                \n",
    "                # оцениваем качество модели на валидационной выборке\n",
    "                predictions = model.predict(features_valid).round()\n",
    "                result = accuracy_score(target_valid, predictions)\n",
    "                print(\n",
    "                    estimators,'\\t', \n",
    "                    test_criterion, '\\t', \n",
    "                    depth,'\\t', \n",
    "                    test_max_features, '\\t', \n",
    "                    result\n",
    "                )   \n",
    "                \n",
    "                # сохраняем лучшую на данный момент модель и ее показатели\n",
    "                if result > best_result:\n",
    "                    best_result = result\n",
    "                    random_forest_regressor_best_model = model\n",
    "                    best_n_estimarots=estimators\n",
    "                    best_criterion=test_criterion\n",
    "                    best_depth = depth\n",
    "                    best_max_features = test_max_features\n",
    "    print()\n",
    "print('--------------------------------------------------')\n",
    "print('best results:')\n",
    "print(best_n_estimarots,'\\t', best_criterion, '\\t', best_depth,'\\t', best_max_features, '\\t', best_result)\n",
    "\n",
    "\n",
    "print(f'best model: {random_forest_regressor_best_model}')\n",
    "\n",
    "# если доля правильных ответов превысит 0,75, сохраним нашу модель в списке лучших \n",
    "if best_result >= 0.75:\n",
    "    best_models.append([random_forest_regressor_best_model, best_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность случайного леса для регрессии превысила порог с 0.75. \n",
    "\n",
    "Значения гиперпараметров: \n",
    "- количество деревьев в лесу - 60\n",
    "- функция, измеряющая качество разбиения - friedman_mse \t\n",
    "- максимальная глубина деревьев - 5\n",
    "- количество характеристик, которые учитываются при поиске лучшего разбиения - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания модели линейной регрессии в задаче классификации также можно трактовать как вероятность попадания в тот или иной класс. \n",
    "\n",
    "Здесь тоже применим к предсказаниям операцию округления и так получим разделение на классы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_intercept \t positive \t accuracy_score\n",
      "True \t \t True \t \t 0.7325038880248833\n",
      "True \t \t False \t \t 0.7325038880248833\n",
      "False \t \t True \t \t 0.7293934681181959\n",
      "False \t \t False \t \t 0.7293934681181959\n",
      "\n",
      "--------------------------------------------------\n",
      "best results:\n",
      "True \t True \t 0.7325038880248833\n",
      "best model: LinearRegression(positive=True)\n"
     ]
    }
   ],
   "source": [
    "# создаем переменные для лучшей на текущий момент модели и ее точности\n",
    "linear_regression_best_model = None\n",
    "best_result = 0\n",
    "\n",
    "print('fit_intercept','\\t','positive', '\\t', 'accuracy_score')\n",
    "\n",
    "# перебираем разные комбинации в цикле\n",
    "for test_fit_intercept in [True, False]:\n",
    "    for test_positive in [True, False]:\n",
    "        model = LinearRegression(\n",
    "            fit_intercept=test_fit_intercept, \n",
    "            positive=test_positive\n",
    "        )\n",
    "        \n",
    "        # обучаем модель на тренировочных данных\n",
    "        model.fit(features_train, target_train)\n",
    "        \n",
    "        # оцениваем качество модели на валидационной выборке\n",
    "        predictions = model.predict(features_valid).round()\n",
    "        result = accuracy_score(target_valid, predictions)\n",
    "        print(test_fit_intercept,'\\t','\\t',test_positive, '\\t','\\t', result)\n",
    "        \n",
    "        # сохраняем лучшую на данный момент модель и ее показатели\n",
    "        if result > best_result:\n",
    "            best_result = result\n",
    "            linear_regression_best_model = model\n",
    "            best_fit_intercept=test_fit_intercept\n",
    "            best_positive=test_positive\n",
    "            \n",
    "print()\n",
    "print('--------------------------------------------------')\n",
    "print('best results:')\n",
    "print(best_fit_intercept,'\\t', best_positive, '\\t', best_result)\n",
    "\n",
    "\n",
    "print(f'best model: {linear_regression_best_model}')\n",
    "\n",
    "# если доля правильных ответов превысит 0,75, сохраним нашу модель в списке лучших \n",
    "if best_result >= 0.75:\n",
    "    best_models.append([linear_regression_best_model, best_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимальная достигнутая точность модели линейной регрессии не превысила заданного порога в 0,75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[DecisionTreeClassifier(max_depth=5, max_features=3, random_state=12345),\n",
       "  0.7931570762052877],\n",
       " [RandomForestClassifier(max_depth=5, max_features=4, n_estimators=60,\n",
       "                         random_state=12345),\n",
       "  0.8133748055987559],\n",
       " [DecisionTreeRegressor(criterion='friedman_mse', max_depth=5, max_features=3,\n",
       "                        random_state=12345),\n",
       "  0.7931570762052877],\n",
       " [RandomForestRegressor(criterion='friedman_mse', max_depth=5, max_features=4,\n",
       "                        n_estimators=60, random_state=12345),\n",
       "  0.8133748055987559]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем список моделей, которые достигли нужной нам точности предсказаний\n",
    "best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выводы**\n",
    "\n",
    "1. Мы настроили параметры и обучили 6 моделей: решающее дерево, случайный лес, логистическую регрессию, дерево решений для регрессии, случайный лес для регрессии и линейную регрессию. \n",
    "\n",
    "\n",
    "2. Из них заданный порог точности не преодолели только модели логистической и линейной регрессии.\n",
    "\n",
    "\n",
    "3. Лучшее значение точности модели у случайного леса - 0.813.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверьте модель на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=5, max_features=3, random_state=12345)\n",
      "точность на валидационной выборке 0.7931570762052877\n",
      "точность на тестовой выборке 0.80248833592535\n",
      "\n",
      "RandomForestClassifier(max_depth=5, max_features=4, n_estimators=60,\n",
      "                       random_state=12345)\n",
      "точность на валидационной выборке 0.8133748055987559\n",
      "точность на тестовой выборке 0.8211508553654744\n",
      "\n",
      "DecisionTreeRegressor(criterion='friedman_mse', max_depth=5, max_features=3,\n",
      "                      random_state=12345)\n",
      "точность на валидационной выборке 0.7931570762052877\n",
      "точность на тестовой выборке 0.80248833592535\n",
      "\n",
      "RandomForestRegressor(criterion='friedman_mse', max_depth=5, max_features=4,\n",
      "                      n_estimators=60, random_state=12345)\n",
      "точность на валидационной выборке 0.8133748055987559\n",
      "точность на тестовой выборке 0.8211508553654744\n",
      "\n",
      "------------------------------\n",
      "best model\n",
      "RandomForestClassifier(max_depth=5, max_features=4, n_estimators=60,\n",
      "                       random_state=12345) 0.8211508553654744\n"
     ]
    }
   ],
   "source": [
    "# создадим переменные для лучшей модели\n",
    "best_model = None\n",
    "best_result = 0\n",
    "\n",
    "for test_model in best_models:\n",
    "    # предсказания модели на тестовых характеристиках\n",
    "    predictions = test_model[0].predict(features_test).round()\n",
    "    \n",
    "    # вычисляем точность\n",
    "    result = accuracy_score(target_test, predictions)\n",
    "    print(test_model[0])\n",
    "    print('точность на валидационной выборке', test_model[1])\n",
    "    print('точность на тестовой выборке', result)\n",
    "    \n",
    "    if result > best_result:\n",
    "        best_model = test_model[0]\n",
    "        best_result = result\n",
    "    print()\n",
    "print('------------------------------')\n",
    "print('best model')\n",
    "print(best_model, best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- При проверке <u>на тестовой выборке все модели показали более высокие результаты</u>, чем на этапе валидационной проверки.\n",
    "\n",
    "- **Самой точной оказалась модель** классификации с помощью **случайного леса**: точность - 0.821."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Улучшение модели случайного леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем улучшить модель случайного леса. Обучим ее на объединении тренировочной и валидационной выборок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединим переменные с обучающими признаками для тренировочной и валидационной выборок\n",
    "features_train_new = pd.concat([features_train, features_valid])\n",
    "features_train.shape[0] + features_valid.shape[0] == features_train_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# объединим переменные с целевым признаком для тренировочной и валидационной выборок\n",
    "target_train_new = pd.concat([target_train, target_valid])\n",
    "target_train.shape[0] + target_valid.shape[0] == target_train_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.693504\n",
       "1    0.306496\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим, сохранилось ли соотношение классов\n",
    "target_train_new.value_counts()/target_train_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8242612752721618"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучим модель на объединенных данных\n",
    "model = RandomForestClassifier(\n",
    "    max_depth=5, \n",
    "    max_features=4, \n",
    "    n_estimators=60,\n",
    "    random_state=12345\n",
    ")\n",
    "\n",
    "# проверим точность предсказаний\n",
    "model.fit(features_train_new, target_train_new)\n",
    "predictions = model.predict(features_test)\n",
    "accuracy_score(predictions, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обучения модели случайного леса на большем количестве данных, точность модели повысилась до 0,824."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (бонус) Проверьте модели на адекватность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результат с наивным прогнозом, когда для всех элементов будем делать прогноз по самому частотному классу. То есть доля самого частотного класса в выборке и будет качеством такой модели (так как такие позиции будут спрогнозированы верно). Наша модель будет адекватной, если ее качество будет выше качества наивного прогноза.\n",
    "\n",
    "Для проверки используем DummyClassifier из ScikitLearn. В качестве стратегии выберем most_frequent, то есть метод predict будет всегда возвращать самый частотный класс, который выделит на тренировочных данных (в данном случае это 0, что соответствует тарифу «Смарт»)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6936236391912908"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучим модель на тренировочных данных и вычислим ее точность на тестовых.\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(features_train, target_train)\n",
    "\n",
    "predictions = dummy_clf.predict(features_test)\n",
    "accuracy_score(target_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Показатели точности для всех четырех моделей превышают 0.693. Следовательно, все четыре модели являются адекватными."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Оператор мобильной связи «Мегалайн» хочет построить систему, способную проанализировать поведение клиентов и предложить пользователям новый тариф: «Смарт» или «Ультра».\n",
    "В нашем распоряжении данные о поведении клиентов, которые уже перешли на эти тарифы, в общей сложности о 3214 пользователях. Данные прошли предобработку, пропусков не содержат. Пользователи выбирают тариф «Смарт» более чем в 2 раза чаще, чем тариф «Ультра».\n",
    "\n",
    "2. Мы разделили исходные данные на три части – обучающую выборку, валидационную и тестовую в отношении 3:1:1. Соотношение данных по разным тарифам при этом сохранилось. \n",
    "\n",
    "3. Мы настроили параметры и обучили 6 моделей: \n",
    "- решающее дерево, \n",
    "- случайный лес, \n",
    "- логистическую регрессию, \n",
    "- дерево решений для регрессии, \n",
    "- случайный лес для регрессии \n",
    "- линейную регрессию. \n",
    "4. Из этих моделей заданный в 0,75 порог точности преодолели:\n",
    "- решающее дерево (0.79), \n",
    "- случайный лес (0.81), \n",
    "- дерево решений для регрессии (0.79), \n",
    "- случайный лес для регрессии (0.81). \n",
    " \n",
    "**Лучшее значение точности модели у случайного леса - 0.813**.\n",
    "\n",
    "5. При проверке на тестовой выборке все модели показали более высокие результаты, чем на этапе валидационной проверки.\n",
    "**Самой точной** снова оказалась модель классификации с помощью **случайного леса: точность - 0.821**.\n",
    "\n",
    "6. Удалось еще повысить точность модели случайного леса до 0.824 за счет обучения ее на объединении тренировочной и валидационной выборок.\n",
    "\n",
    "7. Адекватность моделей проверялась с помощью DummyClassifier, настроенного так, чтобы всегда возвращать самый частотный класс. Точность такой модели составила 0.693. Показатели точности для всех четырех моделей превышают этот уровень. Следовательно, все четыре модели являются адекватными.\n",
    "\n",
    "\n",
    "**Таким образом, лучшей моделью является модель RandomForestClassifier со следующими значениями гиперпараметров**: \n",
    "- количество деревьев - 60\n",
    "- максимальная глубина деревьев - 5\n",
    "- количество характеристик, которые учитываются при поиске лучшего разбиения – 4.\n",
    "\n",
    "**На тестовых данных модель достигла точности 0.824**.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 438,
    "start_time": "2023-03-01T12:47:50.838Z"
   },
   {
    "duration": 88,
    "start_time": "2023-03-01T12:48:01.456Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-01T12:48:21.558Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-01T12:48:29.310Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-01T12:57:15.617Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-01T12:59:38.158Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-01T12:59:43.765Z"
   },
   {
    "duration": 492,
    "start_time": "2023-03-01T16:37:17.217Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-01T16:37:21.040Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-01T16:37:23.872Z"
   },
   {
    "duration": 992,
    "start_time": "2023-03-01T16:37:39.323Z"
   },
   {
    "duration": 495,
    "start_time": "2023-03-01T16:37:44.442Z"
   },
   {
    "duration": 603,
    "start_time": "2023-03-01T16:38:06.649Z"
   },
   {
    "duration": 27,
    "start_time": "2023-03-01T16:44:06.884Z"
   },
   {
    "duration": 450,
    "start_time": "2023-03-01T16:45:18.587Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-01T16:45:22.687Z"
   },
   {
    "duration": 402,
    "start_time": "2023-03-03T13:54:36.219Z"
   },
   {
    "duration": 100,
    "start_time": "2023-03-03T13:54:38.960Z"
   },
   {
    "duration": 42,
    "start_time": "2023-03-03T13:55:18.780Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-03T13:59:15.320Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-03T13:59:16.616Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-03T13:59:17.922Z"
   },
   {
    "duration": 943,
    "start_time": "2023-03-03T13:59:24.238Z"
   },
   {
    "duration": 26,
    "start_time": "2023-03-03T13:59:28.155Z"
   },
   {
    "duration": 83,
    "start_time": "2023-03-03T14:00:52.738Z"
   },
   {
    "duration": 730,
    "start_time": "2023-03-03T14:01:14.328Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T14:01:19.152Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T14:01:42.576Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-03T14:02:32.354Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T14:02:34.800Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-03T14:02:38.262Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T14:06:39.752Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T14:08:41.770Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-03T14:09:00.349Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-03T14:12:15.329Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T14:13:00.068Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-03T14:27:46.816Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-03T14:31:03.059Z"
   },
   {
    "duration": 193,
    "start_time": "2023-03-03T14:48:29.543Z"
   },
   {
    "duration": 156,
    "start_time": "2023-03-03T14:51:44.989Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T14:52:00.601Z"
   },
   {
    "duration": 148,
    "start_time": "2023-03-03T14:53:40.756Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T14:53:47.849Z"
   },
   {
    "duration": 2,
    "start_time": "2023-03-03T14:58:23.897Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-03T14:59:09.624Z"
   },
   {
    "duration": 3359,
    "start_time": "2023-03-03T15:08:29.820Z"
   },
   {
    "duration": 146504,
    "start_time": "2023-03-03T15:10:05.139Z"
   },
   {
    "duration": 15997,
    "start_time": "2023-03-03T15:18:23.677Z"
   },
   {
    "duration": 31658,
    "start_time": "2023-03-03T15:18:45.502Z"
   },
   {
    "duration": 27908,
    "start_time": "2023-03-03T15:20:25.022Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T15:21:18.410Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-03T15:21:32.419Z"
   },
   {
    "duration": 148,
    "start_time": "2023-03-03T15:21:35.709Z"
   },
   {
    "duration": 27551,
    "start_time": "2023-03-03T15:21:43.900Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T15:22:15.838Z"
   },
   {
    "duration": 44,
    "start_time": "2023-03-03T15:23:55.607Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-03T15:30:05.485Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T15:30:17.642Z"
   },
   {
    "duration": 894,
    "start_time": "2023-03-03T15:30:24.786Z"
   },
   {
    "duration": 2521,
    "start_time": "2023-03-03T15:30:44.502Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T15:37:28.221Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-03T15:41:25.370Z"
   },
   {
    "duration": 2491,
    "start_time": "2023-03-03T15:41:32.937Z"
   },
   {
    "duration": 2502,
    "start_time": "2023-03-03T15:42:00.301Z"
   },
   {
    "duration": 1707,
    "start_time": "2023-03-03T15:42:47.028Z"
   },
   {
    "duration": 885,
    "start_time": "2023-03-03T15:43:03.275Z"
   },
   {
    "duration": 866,
    "start_time": "2023-03-03T15:43:28.106Z"
   },
   {
    "duration": 891,
    "start_time": "2023-03-03T15:49:38.992Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T15:49:54.101Z"
   },
   {
    "duration": 1135,
    "start_time": "2023-03-03T17:51:30.785Z"
   },
   {
    "duration": 96,
    "start_time": "2023-03-03T17:51:31.922Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-03T17:51:32.019Z"
   },
   {
    "duration": 987,
    "start_time": "2023-03-03T17:51:32.032Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-03T17:51:33.022Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T17:51:33.046Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T17:51:33.053Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-03T17:51:33.059Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-03T17:51:33.070Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T17:51:33.111Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T17:51:33.121Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T17:51:33.131Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-03T17:51:33.140Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-03T17:51:33.151Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T17:51:33.165Z"
   },
   {
    "duration": 198,
    "start_time": "2023-03-03T17:51:33.173Z"
   },
   {
    "duration": 28378,
    "start_time": "2023-03-03T17:51:33.373Z"
   },
   {
    "duration": 950,
    "start_time": "2023-03-03T17:52:01.753Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T17:54:14.198Z"
   },
   {
    "duration": 112,
    "start_time": "2023-03-03T17:54:50.702Z"
   },
   {
    "duration": 213,
    "start_time": "2023-03-03T17:56:08.800Z"
   },
   {
    "duration": 453,
    "start_time": "2023-03-03T17:56:24.080Z"
   },
   {
    "duration": 395,
    "start_time": "2023-03-03T18:18:29.373Z"
   },
   {
    "duration": 382,
    "start_time": "2023-03-03T18:18:45.700Z"
   },
   {
    "duration": 362,
    "start_time": "2023-03-03T18:18:59.598Z"
   },
   {
    "duration": 360,
    "start_time": "2023-03-03T18:19:07.773Z"
   },
   {
    "duration": 87,
    "start_time": "2023-03-03T18:20:59.467Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-03T18:33:42.482Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-03T18:33:52.015Z"
   },
   {
    "duration": 48,
    "start_time": "2023-03-03T18:34:01.120Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-03T18:34:15.867Z"
   },
   {
    "duration": 50712,
    "start_time": "2023-03-03T18:34:30.268Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T18:38:46.284Z"
   },
   {
    "duration": 42,
    "start_time": "2023-03-03T18:38:46.290Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-03T18:38:46.333Z"
   },
   {
    "duration": 546,
    "start_time": "2023-03-03T18:38:46.347Z"
   },
   {
    "duration": 30,
    "start_time": "2023-03-03T18:38:46.895Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T18:38:46.927Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T18:38:46.934Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T18:38:46.941Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T18:38:46.951Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T18:38:46.959Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T18:38:46.968Z"
   },
   {
    "duration": 38,
    "start_time": "2023-03-03T18:38:46.976Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T18:38:47.016Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T18:38:47.026Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T18:38:47.033Z"
   },
   {
    "duration": 195,
    "start_time": "2023-03-03T18:38:47.039Z"
   },
   {
    "duration": 28475,
    "start_time": "2023-03-03T18:38:47.236Z"
   },
   {
    "duration": 918,
    "start_time": "2023-03-03T18:39:15.713Z"
   },
   {
    "duration": 362,
    "start_time": "2023-03-03T18:39:16.633Z"
   },
   {
    "duration": 47,
    "start_time": "2023-03-03T18:39:16.997Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-03T18:39:17.046Z"
   },
   {
    "duration": 48285,
    "start_time": "2023-03-03T18:39:27.138Z"
   },
   {
    "duration": 49428,
    "start_time": "2023-03-03T18:41:22.167Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T18:44:55.471Z"
   },
   {
    "duration": 36,
    "start_time": "2023-03-03T18:44:55.482Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-03T18:44:55.521Z"
   },
   {
    "duration": 747,
    "start_time": "2023-03-03T18:44:55.539Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-03T18:44:56.288Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-03T18:44:56.326Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T18:44:56.338Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-03T18:44:56.347Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-03T18:44:56.359Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-03T18:44:56.371Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T18:44:56.421Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T18:44:56.431Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-03T18:44:56.442Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T18:44:56.454Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T18:44:56.462Z"
   },
   {
    "duration": 281,
    "start_time": "2023-03-03T18:44:56.470Z"
   },
   {
    "duration": 32991,
    "start_time": "2023-03-03T18:44:56.753Z"
   },
   {
    "duration": 1070,
    "start_time": "2023-03-03T18:45:29.746Z"
   },
   {
    "duration": 536,
    "start_time": "2023-03-03T18:45:30.818Z"
   },
   {
    "duration": 56698,
    "start_time": "2023-03-03T18:45:31.356Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T18:46:59.223Z"
   },
   {
    "duration": 70,
    "start_time": "2023-03-03T18:54:17.621Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-03T18:58:19.863Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-03T18:58:50.462Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-03T19:00:56.385Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-03T19:01:03.623Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-03T19:01:33.859Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-03T19:01:39.109Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-03T19:06:31.676Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-03T19:06:54.656Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-03T19:07:08.997Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-03T19:07:15.908Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-03T19:09:06.893Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T19:12:32.966Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-03T19:14:13.077Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-03T19:14:50.379Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-03T19:15:57.715Z"
   },
   {
    "duration": 32,
    "start_time": "2023-03-03T19:16:16.738Z"
   },
   {
    "duration": 37,
    "start_time": "2023-03-03T19:16:44.066Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T19:38:32.217Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-03T19:38:32.224Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-03T19:38:32.264Z"
   },
   {
    "duration": 569,
    "start_time": "2023-03-03T19:38:32.282Z"
   },
   {
    "duration": 21,
    "start_time": "2023-03-03T19:38:32.854Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T19:38:32.877Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T19:38:32.884Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-03T19:38:32.890Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-03T19:38:32.920Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T19:38:32.931Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T19:38:32.940Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T19:38:32.949Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T19:38:32.960Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T19:38:33.013Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T19:38:33.023Z"
   },
   {
    "duration": 206,
    "start_time": "2023-03-03T19:38:33.029Z"
   },
   {
    "duration": 28135,
    "start_time": "2023-03-03T19:38:33.238Z"
   },
   {
    "duration": 949,
    "start_time": "2023-03-03T19:39:01.375Z"
   },
   {
    "duration": 406,
    "start_time": "2023-03-03T19:39:02.326Z"
   },
   {
    "duration": 34819,
    "start_time": "2023-03-03T19:39:02.735Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-03T19:39:37.556Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-03T19:39:37.557Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-03T19:39:37.558Z"
   },
   {
    "duration": 21640,
    "start_time": "2023-03-03T19:39:39.532Z"
   },
   {
    "duration": 15280,
    "start_time": "2023-03-03T19:40:02.364Z"
   },
   {
    "duration": 48596,
    "start_time": "2023-03-03T19:40:18.701Z"
   },
   {
    "duration": 34,
    "start_time": "2023-03-03T19:41:26.064Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-03T19:41:30.418Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-03T19:41:35.986Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T19:51:06.957Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T19:53:32.138Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T20:00:11.816Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-03T20:03:38.008Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-03T20:17:50.875Z"
   },
   {
    "duration": 70,
    "start_time": "2023-03-03T20:36:51.660Z"
   },
   {
    "duration": 1116,
    "start_time": "2023-03-03T20:50:36.678Z"
   },
   {
    "duration": 42,
    "start_time": "2023-03-03T20:50:37.795Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-03T20:50:37.838Z"
   },
   {
    "duration": 738,
    "start_time": "2023-03-03T20:50:37.850Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-03T20:50:38.590Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T20:50:38.624Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T20:50:38.631Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-03T20:50:38.637Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T20:50:38.653Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T20:50:38.659Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T20:50:38.666Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T20:50:38.672Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T20:50:38.711Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-03T20:50:38.721Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-03T20:50:38.728Z"
   },
   {
    "duration": 186,
    "start_time": "2023-03-03T20:50:38.734Z"
   },
   {
    "duration": 27184,
    "start_time": "2023-03-03T20:50:38.921Z"
   },
   {
    "duration": 859,
    "start_time": "2023-03-03T20:51:06.111Z"
   },
   {
    "duration": 398,
    "start_time": "2023-03-03T20:51:06.972Z"
   },
   {
    "duration": 46757,
    "start_time": "2023-03-03T20:51:07.371Z"
   },
   {
    "duration": 33,
    "start_time": "2023-03-03T20:51:54.130Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-03T20:51:54.165Z"
   },
   {
    "duration": 60,
    "start_time": "2023-03-03T20:51:54.174Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-03T20:51:54.235Z"
   },
   {
    "duration": 1937,
    "start_time": "2023-03-04T06:49:55.682Z"
   },
   {
    "duration": 140,
    "start_time": "2023-03-04T06:49:57.621Z"
   },
   {
    "duration": 11,
    "start_time": "2023-03-04T06:49:57.763Z"
   },
   {
    "duration": 993,
    "start_time": "2023-03-04T06:49:57.776Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-04T06:49:58.772Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-04T06:49:58.798Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-04T06:49:58.806Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-04T06:49:58.813Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-04T06:49:58.848Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-04T06:49:58.866Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-04T06:49:58.876Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-04T06:49:58.885Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-04T06:49:58.896Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-04T06:49:58.909Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-04T06:49:58.917Z"
   },
   {
    "duration": 165,
    "start_time": "2023-03-04T06:49:58.924Z"
   },
   {
    "duration": 27763,
    "start_time": "2023-03-04T06:49:59.091Z"
   },
   {
    "duration": 914,
    "start_time": "2023-03-04T06:50:26.859Z"
   },
   {
    "duration": 365,
    "start_time": "2023-03-04T06:50:27.774Z"
   },
   {
    "duration": 46800,
    "start_time": "2023-03-04T06:50:28.152Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-04T06:51:14.962Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-04T06:51:14.988Z"
   },
   {
    "duration": 31,
    "start_time": "2023-03-04T06:51:14.994Z"
   },
   {
    "duration": 36,
    "start_time": "2023-03-04T06:51:15.026Z"
   },
   {
    "duration": 50,
    "start_time": "2023-03-04T07:55:41.255Z"
   },
   {
    "duration": 1094,
    "start_time": "2023-03-04T07:55:49.214Z"
   },
   {
    "duration": 135,
    "start_time": "2023-03-04T07:55:50.310Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-04T07:55:50.446Z"
   },
   {
    "duration": 892,
    "start_time": "2023-03-04T07:55:50.457Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-04T07:55:51.351Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-04T07:55:51.373Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-04T07:55:51.406Z"
   },
   {
    "duration": 9,
    "start_time": "2023-03-04T07:55:51.411Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-04T07:55:51.421Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-04T07:55:51.428Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-04T07:55:51.435Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-04T07:55:51.442Z"
   },
   {
    "duration": 23,
    "start_time": "2023-03-04T07:55:51.464Z"
   },
   {
    "duration": 35,
    "start_time": "2023-03-04T07:55:51.489Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-04T07:55:51.525Z"
   },
   {
    "duration": 179,
    "start_time": "2023-03-04T07:55:51.539Z"
   },
   {
    "duration": 58391,
    "start_time": "2023-03-04T07:55:51.720Z"
   },
   {
    "duration": 1819,
    "start_time": "2023-03-04T07:56:50.112Z"
   },
   {
    "duration": 774,
    "start_time": "2023-03-04T07:56:51.933Z"
   },
   {
    "duration": 3,
    "start_time": "2023-03-04T07:58:43.149Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-04T07:58:43.154Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-04T07:58:43.199Z"
   },
   {
    "duration": 517,
    "start_time": "2023-03-04T07:58:43.213Z"
   },
   {
    "duration": 20,
    "start_time": "2023-03-04T07:58:43.733Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-04T07:58:43.755Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-04T07:58:43.762Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-04T07:58:43.806Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-04T07:58:43.813Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-04T07:58:43.825Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-04T07:58:43.838Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-04T07:58:43.846Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-04T07:58:43.855Z"
   },
   {
    "duration": 34,
    "start_time": "2023-03-04T07:58:43.865Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-04T07:58:43.901Z"
   },
   {
    "duration": 144,
    "start_time": "2023-03-04T07:58:43.910Z"
   },
   {
    "duration": 26988,
    "start_time": "2023-03-04T07:58:44.055Z"
   },
   {
    "duration": 837,
    "start_time": "2023-03-04T07:59:11.044Z"
   },
   {
    "duration": 350,
    "start_time": "2023-03-04T07:59:11.883Z"
   },
   {
    "duration": 48026,
    "start_time": "2023-03-04T07:59:12.234Z"
   },
   {
    "duration": 45,
    "start_time": "2023-03-04T08:00:00.261Z"
   },
   {
    "duration": 19,
    "start_time": "2023-03-04T08:00:00.308Z"
   },
   {
    "duration": 60,
    "start_time": "2023-03-04T08:00:00.328Z"
   },
   {
    "duration": 0,
    "start_time": "2023-03-04T08:00:00.389Z"
   },
   {
    "duration": 28,
    "start_time": "2023-03-04T08:20:42.206Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-04T08:24:44.333Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-04T08:25:44.924Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-04T08:26:24.487Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-04T08:27:40.631Z"
   },
   {
    "duration": 15,
    "start_time": "2023-03-04T08:28:00.694Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-04T08:28:41.853Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-04T08:28:51.067Z"
   },
   {
    "duration": 229,
    "start_time": "2023-03-04T08:31:03.194Z"
   },
   {
    "duration": 1122,
    "start_time": "2023-03-04T08:56:38.329Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-04T08:56:39.453Z"
   },
   {
    "duration": 16,
    "start_time": "2023-03-04T08:56:39.505Z"
   },
   {
    "duration": 852,
    "start_time": "2023-03-04T08:56:39.524Z"
   },
   {
    "duration": 40,
    "start_time": "2023-03-04T08:56:40.378Z"
   },
   {
    "duration": 41,
    "start_time": "2023-03-04T08:56:40.420Z"
   },
   {
    "duration": 4,
    "start_time": "2023-03-04T08:56:40.463Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-04T08:56:40.468Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-04T08:56:40.481Z"
   },
   {
    "duration": 43,
    "start_time": "2023-03-04T08:56:40.491Z"
   },
   {
    "duration": 7,
    "start_time": "2023-03-04T08:56:40.536Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-04T08:56:40.544Z"
   },
   {
    "duration": 10,
    "start_time": "2023-03-04T08:56:40.550Z"
   },
   {
    "duration": 13,
    "start_time": "2023-03-04T08:56:40.561Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-04T08:56:40.575Z"
   },
   {
    "duration": 185,
    "start_time": "2023-03-04T08:56:40.581Z"
   },
   {
    "duration": 30261,
    "start_time": "2023-03-04T08:56:40.767Z"
   },
   {
    "duration": 932,
    "start_time": "2023-03-04T08:57:11.030Z"
   },
   {
    "duration": 413,
    "start_time": "2023-03-04T08:57:11.964Z"
   },
   {
    "duration": 52456,
    "start_time": "2023-03-04T08:57:12.391Z"
   },
   {
    "duration": 24,
    "start_time": "2023-03-04T08:58:04.848Z"
   },
   {
    "duration": 12,
    "start_time": "2023-03-04T08:58:04.892Z"
   },
   {
    "duration": 51,
    "start_time": "2023-03-04T08:58:04.906Z"
   },
   {
    "duration": 6,
    "start_time": "2023-03-04T08:58:04.959Z"
   },
   {
    "duration": 8,
    "start_time": "2023-03-04T08:58:04.966Z"
   },
   {
    "duration": 39,
    "start_time": "2023-03-04T08:58:04.975Z"
   },
   {
    "duration": 236,
    "start_time": "2023-03-04T08:58:05.016Z"
   },
   {
    "duration": 5,
    "start_time": "2023-03-04T08:58:05.256Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "274.167px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
